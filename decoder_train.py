#!/usr/bin/env python3
"""
å¼¹æ€§åˆ†æ”¯è®­ç»ƒ - å¯ä»¥æŒ‡å®šè®­ç»ƒroot/trans/poseåˆ†æ”¯
æ”¯æŒæ–­ç‚¹ç»­è®­åŠŸèƒ½
è®­ç»ƒæ—¶åªä¿å­˜å½“å‰è®­ç»ƒåˆ†æ”¯çš„æƒé‡
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import argparse
from pathlib import Path
import pickle
import numpy as np
from typing import Dict, List, Tuple, Optional
from tqdm import tqdm
import traceback
from scipy.interpolate import interp1d
import sys
import signal
import json
import math
import time

# å¯¼å…¥å¼¹æ€§è¿åŠ¨è§£ç å™¨
from ltx_video.models.autoencoders.motion_decoder import ElasticMotionDecoder, create_elastic_motion_decoder_config


def interpolate_motion_to_target_frames(
        motion: np.ndarray,
        source_frames: int,
        target_frames: int,
        method: str = 'linear'
) -> np.ndarray:
    """
    å°†è¿åŠ¨æ•°æ®ä»source_framesæ’å€¼åˆ°target_frames
    """
    if source_frames == target_frames:
        return motion.copy()

    source_time = np.linspace(0, 1, source_frames)
    target_time = np.linspace(0, 1, target_frames)

    interpolated = np.zeros((target_frames, motion.shape[1]), dtype=motion.dtype)

    for d in range(motion.shape[1]):
        f = interp1d(source_time, motion[:, d], kind='linear',
                     fill_value='extrapolate', bounds_error=False)
        interpolated[:, d] = f(target_time)

    return interpolated


class RootOnlyLoss(nn.Module):
    """åªè®­ç»ƒrootåˆ†æ”¯çš„æŸå¤±å‡½æ•°"""

    def __init__(self):
        super().__init__()
        self.position_loss = nn.SmoothL1Loss()

    def compute_velocity(self, motion):
        """è®¡ç®—é€Ÿåº¦ï¼ˆä¸€é˜¶å·®åˆ†ï¼‰"""
        velocity = motion[..., 1:, :] - motion[..., :-1, :]
        return velocity

    def compute_acceleration(self, motion):
        """è®¡ç®—åŠ é€Ÿåº¦ï¼ˆäºŒé˜¶å·®åˆ†ï¼‰"""
        velocity = self.compute_velocity(motion)
        acceleration = velocity[..., 1:, :] - velocity[..., :-1, :]
        return acceleration

    def forward(self, pred_root, target_root):
        # 1. ä½ç½®æŸå¤±
        pos_loss = self.position_loss(pred_root, target_root)

        # 2. é€Ÿåº¦æŸå¤±
        pred_vel = self.compute_velocity(pred_root)
        target_vel = self.compute_velocity(target_root)
        vel_loss = self.position_loss(pred_vel, target_vel)

        # 3. åŠ é€Ÿåº¦æŸå¤±
        pred_acc = self.compute_acceleration(pred_root)
        target_acc = self.compute_acceleration(target_root)
        acc_loss = self.position_loss(pred_acc, target_acc)

        # æ€»æŸå¤± - ç»Ÿä¸€æƒé‡
        total_loss = pos_loss + vel_loss + acc_loss

        return total_loss


class TransOnlyLoss(nn.Module):
    """åªè®­ç»ƒtransåˆ†æ”¯çš„æŸå¤±å‡½æ•°"""

    def __init__(self):
        super().__init__()
        self.position_loss = nn.SmoothL1Loss()

    def forward(self, pred_trans, target_trans):
        # transåªæœ‰ä½ç½®æŸå¤±
        trans_loss = self.position_loss(pred_trans, target_trans)
        return trans_loss


class PoseOnlyLoss(nn.Module):
    """åªè®­ç»ƒposeåˆ†æ”¯çš„æŸå¤±å‡½æ•°"""

    def __init__(self):
        super().__init__()
        self.position_loss = nn.SmoothL1Loss()

    def forward(self, pred_pose, target_pose):
        # poseåªæœ‰ä½ç½®æŸå¤±
        pose_loss = self.position_loss(pred_pose, target_pose)
        return pose_loss


class LTXMotionDataset(Dataset):
    """ä¸ºltxè§£ç å™¨å‡†å¤‡çš„æ•°æ®é›†"""

    def __init__(
            self,
            features_dir: str,
            gt_dir: str,
            temporal_factor: int = 8,
            interpolate_method: str = 'linear'
    ):
        self.features_dir = Path(features_dir)
        self.gt_dir = Path(gt_dir)
        self.temporal_factor = temporal_factor
        self.interpolate_method = interpolate_method

        # è·å–æ‰€æœ‰ç‰¹å¾æ–‡ä»¶
        self.feature_files = sorted(list(self.features_dir.glob("*.pth")))

        if not self.feature_files:
            raise ValueError(f"åœ¨ {features_dir} ä¸­æœªæ‰¾åˆ°.pthç‰¹å¾æ–‡ä»¶")

        print(f"æ‰¾åˆ° {len(self.feature_files)} ä¸ªç‰¹å¾æ–‡ä»¶")

        # åŒ¹é…GTæ–‡ä»¶å¹¶è¿‡æ»¤æ— æ•ˆæ•°æ®
        self.samples = []
        self.invalid_samples = []

        for feature_file in self.feature_files:
            file_id = feature_file.stem
            gt_file = self.gt_dir / f"{file_id}.pkl"

            if not gt_file.exists():
                self.invalid_samples.append((feature_file, f"GTæ–‡ä»¶ä¸å­˜åœ¨: {gt_file}"))
                continue

            try:
                # æ£€æŸ¥ç‰¹å¾æ–‡ä»¶
                feature_data = torch.load(feature_file, map_location='cpu', weights_only=True)
                if isinstance(feature_data, dict):
                    has_tensor = False
                    for value in feature_data.values():
                        if isinstance(value, torch.Tensor) and value.numel() > 0:
                            has_tensor = True
                            break
                    if not has_tensor:
                        self.invalid_samples.append((feature_file, "ç‰¹å¾æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆå¼ é‡"))
                        continue

                # æ£€æŸ¥GTæ–‡ä»¶
                with open(gt_file, 'rb') as f:
                    gt_data = pickle.load(f)

                if 'person1' not in gt_data and 'person2' not in gt_data:
                    self.invalid_samples.append((gt_file, "GTæ–‡ä»¶ä¸­æ²¡æœ‰äººæ•°æ®"))
                    continue

                self.samples.append({
                    'feature_file': feature_file,
                    'gt_file': gt_file,
                    'file_id': file_id
                })

            except Exception as e:
                self.invalid_samples.append((feature_file, f"é¢„æ£€æŸ¥å¤±è´¥: {str(e)}"))
                continue

        print(f"æœ‰æ•ˆæ ·æœ¬æ•°: {len(self.samples)}")
        if self.invalid_samples:
            print(f"è·³è¿‡æ— æ•ˆæ ·æœ¬æ•°: {len(self.invalid_samples)}")
            for i, (file, reason) in enumerate(self.invalid_samples[:5]):
                print(f"  æ— æ•ˆæ ·æœ¬ {i + 1}: {file} - {reason}")
            if len(self.invalid_samples) > 5:
                print(f"  è¿˜æœ‰ {len(self.invalid_samples) - 5} ä¸ªæ— æ•ˆæ ·æœ¬æœªæ˜¾ç¤º...")

        if not self.samples:
            raise ValueError("æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ç‰¹å¾-GTå¯¹")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        try:
            sample = self.samples[idx]

            # åŠ è½½latentç‰¹å¾
            feature_data = torch.load(sample['feature_file'], map_location='cpu', weights_only=True)

            # æå–latentå¼ é‡
            if isinstance(feature_data, dict):
                latent = None
                for key, value in feature_data.items():
                    if isinstance(value, torch.Tensor) and value.numel() > 0:
                        latent = value
                        break
                if latent is None:
                    raise ValueError(f"ç‰¹å¾æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆå¼ é‡æ•°æ®: {sample['feature_file']}")
            elif isinstance(feature_data, torch.Tensor):
                latent = feature_data
                if latent.numel() == 0:
                    raise ValueError(f"ç‰¹å¾å¼ é‡ä¸ºç©º: {sample['feature_file']}")
            else:
                raise ValueError(f"æœªçŸ¥çš„ç‰¹å¾æ•°æ®ç±»å‹: {type(feature_data)}")

            # å¤„ç†ç»´åº¦
            if latent.dim() == 5:  # [B, C, T, H, W]
                if latent.shape[0] == 1:
                    latent = latent.squeeze(0)  # [C, T, H, W]
            elif latent.dim() == 4:  # [C, T, H, W]
                pass
            elif latent.dim() == 3:  # [C, T, D]
                latent = latent.unsqueeze(-1).unsqueeze(-1)  # [C, T, 1, 1]
            else:
                while latent.dim() < 4:
                    latent = latent.unsqueeze(-1)

            if latent.dim() != 4:
                raise ValueError(f"latentç»´åº¦åº”ä¸º4ï¼Œå½“å‰ä¸º{latent.dim()}")

            # è·å–latentçš„å¸§æ•°
            T_latent = latent.shape[1]
            if T_latent == 0:
                raise ValueError(f"latentæ—¶é—´ç»´åº¦ä¸º0: {sample['feature_file']}")

            # è®¡ç®—ç›®æ ‡å¸§æ•°
            target_frames = (T_latent - 1) * self.temporal_factor + 1

            # åŠ è½½GTè¿åŠ¨å‚æ•°
            with open(sample['gt_file'], 'rb') as f:
                gt_data = pickle.load(f)

            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸¤ä¸ªäººçš„æ•°æ®
            has_person1 = 'person1' in gt_data
            has_person2 = 'person2' in gt_data

            # æå–æ‰€æœ‰è¿åŠ¨å‚æ•°
            def extract_motion_params(data):
                params = {}
                for key in ['root_orient', 'pose_body', 'trans']:
                    if key in data:
                        param = data[key]
                        if isinstance(param, torch.Tensor):
                            param = param.cpu.numpy()
                        params[key] = param
                    else:
                        raise ValueError(f"ç¼ºå°‘å­—æ®µ {key} åœ¨ {sample['file_id']}")

                return params

            # è·å–ä¸¤ä¸ªäººçš„è¿åŠ¨å‚æ•°
            motion_params_list = []
            original_frames_list = []

            if has_person1:
                params1 = extract_motion_params(gt_data['person1'])
                original_frames1 = params1['root_orient'].shape[0]

                # æ’å€¼åˆ°ç›®æ ‡å¸§æ•°
                interpolated_params1 = {}
                for key, value in params1.items():
                    if original_frames1 != target_frames:
                        interpolated_params1[key] = interpolate_motion_to_target_frames(
                            value,
                            original_frames1,
                            target_frames,
                            method=self.interpolate_method
                        )
                    else:
                        interpolated_params1[key] = value

                motion_params_list.append(interpolated_params1)
                original_frames_list.append(original_frames1)

            if has_person2:
                params2 = extract_motion_params(gt_data['person2'])
                original_frames2 = params2['root_orient'].shape[0]

                interpolated_params2 = {}
                for key, value in params2.items():
                    if original_frames2 != target_frames:
                        interpolated_params2[key] = interpolate_motion_to_target_frames(
                            value,
                            original_frames2,
                            target_frames,
                            method=self.interpolate_method
                        )
                    else:
                        interpolated_params2[key] = value

                motion_params_list.append(interpolated_params2)
                original_frames_list.append(original_frames2)

            if not motion_params_list:
                raise ValueError(f"GTæ–‡ä»¶ä¸­æœªæ‰¾åˆ°äººç‰©æ•°æ®: {sample['file_id']}")

            # åˆ›å»ºæœ‰æ•ˆå¸§æ©ç 
            valid_masks = []
            for i, original_frames in enumerate(original_frames_list):
                valid_mask = np.zeros(target_frames, dtype=np.float32)
                valid_mask[0] = 1.0
                valid_mask[-1] = 1.0

                if original_frames < target_frames:
                    source_time = np.linspace(0, 1, original_frames)
                    target_time = np.linspace(0, 1, target_frames)

                    for t_src in source_time:
                        idx_target = np.argmin(np.abs(target_time - t_src))
                        valid_mask[idx_target] = 1.0
                else:
                    step = original_frames / target_frames
                    for j in range(target_frames):
                        idx_original = int(j * step)
                        if idx_original < original_frames:
                            valid_mask[j] = 1.0

                valid_masks.append(valid_mask)

            # åˆå¹¶æ¯ä¸ªäººçš„æ•°æ®
            if len(motion_params_list) == 2:
                # ä¸¤ä¸ªäººéƒ½æœ‰æ•°æ®
                root_orient = np.stack([p['root_orient'] for p in motion_params_list])  # [2, T, 3]
                pose_body = np.stack([p['pose_body'] for p in motion_params_list])  # [2, T, pose_dim]
                trans = np.stack([p['trans'] for p in motion_params_list])  # [2, T, 3]
                valid_mask = np.stack(valid_masks)  # [2, T]
                num_persons = 2
            else:
                # åªæœ‰ä¸€ä¸ªäººçš„æ•°æ®ï¼Œå¤åˆ¶ä¸€ä»½ä½œä¸ºç¬¬äºŒä¸ªäºº
                root_orient = np.stack([motion_params_list[0]['root_orient'],
                                        motion_params_list[0]['root_orient']])
                pose_body = np.stack([motion_params_list[0]['pose_body'],
                                      motion_params_list[0]['pose_body']])
                trans = np.stack([motion_params_list[0]['trans'],
                                  motion_params_list[0]['trans']])
                valid_mask = np.stack([valid_masks[0], valid_masks[0]])
                num_persons = 1

            # è½¬æ¢ä¸ºTensor
            root_orient_tensor = torch.from_numpy(root_orient).float()
            pose_body_tensor = torch.from_numpy(pose_body).float()
            trans_tensor = torch.from_numpy(trans).float()
            valid_mask_tensor = torch.from_numpy(valid_mask).float()

            result = {
                'latent': latent,  # [C, T_latent, 1, 1]
                'root_orient': root_orient_tensor,  # [2, target_frames, 3]
                'pose_body': pose_body_tensor,  # [2, target_frames, pose_dim]
                'trans': trans_tensor,  # [2, target_frames, 3]
                'valid_mask': valid_mask_tensor,  # [2, target_frames]
                'file_id': sample['file_id'],
                'target_frames': target_frames,
                'T_latent': T_latent,
                'num_persons': num_persons
            }

            return result

        except Exception as e:
            print(f"è­¦å‘Š: å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {str(e)}")
            next_idx = (idx + 1) % len(self.samples)
            if next_idx != idx:
                return self.__getitem__(next_idx)
            else:
                return self._create_placeholder()

    def _create_placeholder(self):
        """åˆ›å»ºä¸€ä¸ªå ä½ç¬¦æ ·æœ¬"""
        C = 128
        T = 8
        target_frames = (T - 1) * self.temporal_factor + 1
        pose_dim = 63  # å‡è®¾pose_bodyç»´åº¦ä¸º63

        latent = torch.randn(C, T, 1, 1, dtype=torch.float32)
        root_orient = torch.zeros(2, target_frames, 3, dtype=torch.float32)
        pose_body = torch.zeros(2, target_frames, pose_dim, dtype=torch.float32)
        trans = torch.zeros(2, target_frames, 3, dtype=torch.float32)
        valid_mask = torch.ones(2, target_frames, dtype=torch.float32)

        return {
            'latent': latent,
            'root_orient': root_orient,
            'pose_body': pose_body,
            'trans': trans,
            'valid_mask': valid_mask,
            'file_id': 'placeholder',
            'target_frames': target_frames,
            'T_latent': T,
            'num_persons': 2
        }


class ElasticBranchDecoderTrainer:
    """
    å¼¹æ€§åˆ†æ”¯è®­ç»ƒå™¨
    å¯ä»¥æŒ‡å®šè®­ç»ƒroot/trans/poseåˆ†æ”¯ï¼Œå½“è®­ç»ƒä¸‹é™ç¼“æ…¢æ—¶å¼¹æ€§å¢åŠ æ·±åº¦
    æ”¯æŒæ–­ç‚¹ç»­è®­åŠŸèƒ½
    è®­ç»ƒæ—¶åªä¿å­˜å½“å‰è®­ç»ƒåˆ†æ”¯çš„æƒé‡
    """

    def __init__(
            self,
            decoder: ElasticMotionDecoder,
            branch: str = "root",  # "root", "trans", "pose"
            device: str = "cuda",
            learning_rate: float = 1e-4,
            target_loss: float = 0.01,  # ç›®æ ‡æŸå¤±
            patience: int = 5,  # è€å¿ƒå€¼ï¼ˆå¤šå°‘ä¸ªepochç”¨äºè®¡ç®—å¹³å‡æ”¹å–„ï¼‰
            min_improvement: float = 0.001,  # æœ€å°æ”¹å–„é˜ˆå€¼
            max_depth: int = 8,  # æœ€å¤§æ·±åº¦é™åˆ¶
            min_epochs_after_depth_increase: int = 30,  # æ–°å¢æ·±åº¦åè‡³å°‘è®­ç»ƒçš„epochæ•°
            consecutive_failures_required: int = 3,  # è¿ç»­æ£€æŸ¥ä¸è¾¾æ ‡æ¬¡æ•°è¦æ±‚
            checkpoint_path: str = None,  # æ–­ç‚¹ç»­è®­æ£€æŸ¥ç‚¹è·¯å¾„
    ):
        self.branch = branch
        self.device = device
        if device.startswith("cuda") and not torch.cuda.is_available():
            print("è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
            self.device = "cpu"

        print(f"ğŸ”§ è®­ç»ƒå™¨è®¾å¤‡: {self.device}")
        print(f"ğŸ”§ è®­ç»ƒåˆ†æ”¯: {self.branch}")

        # å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡å¹¶éªŒè¯
        self.decoder = decoder.to(self.device)
        self._verify_model_on_device()

        self.target_loss = target_loss
        self.patience = patience
        self.min_improvement = min_improvement
        self.max_depth = max_depth
        self.min_epochs_after_depth_increase = min_epochs_after_depth_increase
        self.consecutive_failures_required = consecutive_failures_required  # æ–°å¢å‚æ•°

        # è®°å½•è®­ç»ƒå†å²
        self.loss_history = []
        self.depth_history = []
        self.lr_history = []
        self.epoch_counter = 0
        self.last_depth_increase_epoch = 0

        # å¼¹æ€§è®­ç»ƒçŠ¶æ€ - æ–°å¢è¿ç»­å¤±è´¥è®¡æ•°å™¨
        self.stagnation_counter = 0
        self.best_loss = float('inf')
        self.last_improvement_epoch = 0
        self.consecutive_check_failures = 0  # æ–°å¢ï¼šè¿ç»­æ£€æŸ¥å¤±è´¥æ¬¡æ•°

        # æ ¹æ®åˆ†æ”¯å†»ç»“å…¶ä»–åˆ†æ”¯
        self._freeze_other_branches()

        # åªä¼˜åŒ–å½“å‰åˆ†æ”¯çš„å‚æ•°
        if self.branch == "root":
            branch_params = list(self.decoder.root_decoder.parameters())
            self.loss_fn = RootOnlyLoss()
        elif self.branch == "trans":
            branch_params = list(self.decoder.trans_decoder.parameters())
            self.loss_fn = TransOnlyLoss()
        elif self.branch == "pose":
            branch_params = list(self.decoder.pose_decoder.parameters())
            self.loss_fn = PoseOnlyLoss()
        else:
            raise ValueError(f"æœªçŸ¥çš„åˆ†æ”¯: {self.branch}")

        print(f"ğŸ”§ {self.branch}åˆ†æ”¯å‚æ•°æ•°é‡: {sum(p.numel() for p in branch_params):,}")

        self.optimizer = optim.AdamW(
            branch_params,
            lr=learning_rate,
            weight_decay=1e-5
        )

        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='min',
            factor=0.5,
            patience=3,
            verbose=True,
            min_lr=1e-6
        )

        # æ–­ç‚¹ç»­è®­ï¼šå¦‚æœæœ‰è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ŒåŠ è½½è®­ç»ƒçŠ¶æ€
        if checkpoint_path and os.path.exists(checkpoint_path):
            self.load_checkpoint(checkpoint_path)
            print(f"âœ“ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒçŠ¶æ€: {checkpoint_path}")

        # ä¸­æ–­å¤„ç†
        self.interrupted = False
        self.setup_interrupt_handler()

        print(f"\n{self.branch}åˆ†æ”¯è®­ç»ƒå™¨åˆå§‹åŒ–:")
        print(f"  è®¾å¤‡: {self.device}")
        print(f"  å­¦ä¹ ç‡: {learning_rate}")
        print(f"  ç›®æ ‡æŸå¤±: {target_loss}")
        print(f"  æœ€å¤§æ·±åº¦: {max_depth}å±‚")
        print(f"  è€å¿ƒå€¼: {patience}ä¸ªepoch")
        print(f"  æœ€å°æ”¹å–„é˜ˆå€¼: {min_improvement}")
        print(f"  å¢åŠ æ·±åº¦åæœ€å°‘è®­ç»ƒepoch: {min_epochs_after_depth_increase}")
        print(f"  è¿ç»­å¤±è´¥è¦æ±‚: {consecutive_failures_required}æ¬¡")
        print(f"  å½“å‰æ·±åº¦: {self._get_current_depth()}å±‚")
        print(f"  å½“å‰epoch: {self.epoch_counter}")

    def _verify_model_on_device(self):
        """éªŒè¯æ•´ä¸ªæ¨¡å‹æ˜¯å¦åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š"""
        device = torch.device(self.device)

        print(f"ğŸ” éªŒè¯æ¨¡å‹è®¾å¤‡ä½ç½®...")

        incorrect_params = []
        for name, param in self.decoder.named_parameters():
            if param.device != device:
                incorrect_params.append((name, param.device))

        if incorrect_params:
            print(f"âš ï¸  å‘ç° {len(incorrect_params)} ä¸ªå‚æ•°åœ¨é”™è¯¯çš„è®¾å¤‡ä¸Š:")
            for name, wrong_device in incorrect_params[:3]:
                print(f"  {name}: {wrong_device} -> ç§»åŠ¨åˆ° {device}")

        print(f"âœ“ æ¨¡å‹éªŒè¯å®Œæˆï¼Œè®¾å¤‡: {device}")

    def _freeze_other_branches(self):
        """å†»ç»“å…¶ä»–åˆ†æ”¯çš„å‚æ•°"""
        if self.branch == "root":
            # å†»ç»“transå’Œpose
            for param in self.decoder.trans_decoder.parameters():
                param.requires_grad = False
            for param in self.decoder.pose_decoder.parameters():
                param.requires_grad = False
            print("âœ“ å†»ç»“transå’Œposeåˆ†æ”¯")
        elif self.branch == "trans":
            # å†»ç»“rootå’Œpose
            for param in self.decoder.root_decoder.parameters():
                param.requires_grad = False
            for param in self.decoder.pose_decoder.parameters():
                param.requires_grad = False
            print("âœ“ å†»ç»“rootå’Œposeåˆ†æ”¯")
        elif self.branch == "pose":
            # å†»ç»“rootå’Œtrans
            for param in self.decoder.root_decoder.parameters():
                param.requires_grad = False
            for param in self.decoder.trans_decoder.parameters():
                param.requires_grad = False
            print("âœ“ å†»ç»“rootå’Œtransåˆ†æ”¯")

    def _get_current_depth(self):
        """è·å–å½“å‰åˆ†æ”¯çš„æ·±åº¦"""
        if self.branch == "root":
            return self.decoder.root_decoder.get_current_depth()
        elif self.branch == "trans":
            return self.decoder.trans_decoder.get_current_depth()
        elif self.branch == "pose":
            return self.decoder.pose_decoder.get_current_depth()
        else:
            return 2  # é»˜è®¤å€¼

    def _is_at_max_depth(self):
        """æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ·±åº¦"""
        current_depth = self._get_current_depth()
        return current_depth >= self.max_depth

    def _extract_branch_state_dict(self):
        """æå–å½“å‰è®­ç»ƒåˆ†æ”¯çš„çŠ¶æ€å­—å…¸"""
        if self.branch == "root":
            prefix = "root_decoder."
        elif self.branch == "trans":
            prefix = "trans_decoder."
        elif self.branch == "pose":
            prefix = "pose_decoder."
        else:
            return {}
        
        branch_state_dict = {}
        full_state_dict = self.decoder.state_dict()
        
        for key, value in full_state_dict.items():
            if key.startswith(prefix):
                # ç§»é™¤åˆ†æ”¯å‰ç¼€
                new_key = key[len(prefix):]
                branch_state_dict[new_key] = value
        
        return branch_state_dict

    def load_checkpoint(self, checkpoint_path: str):
        """ä»æ£€æŸ¥ç‚¹åŠ è½½å®Œæ•´çš„è®­ç»ƒçŠ¶æ€"""
        print(f"ğŸ“¥ ä»æ£€æŸ¥ç‚¹åŠ è½½è®­ç»ƒçŠ¶æ€: {checkpoint_path}")

        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=True)

        # æ£€æŸ¥åˆ†æ”¯æ˜¯å¦åŒ¹é…
        checkpoint_branch = checkpoint.get('branch', self.branch)
        if checkpoint_branch != self.branch:
            print(f"âš ï¸  è­¦å‘Š: æ£€æŸ¥ç‚¹åˆ†æ”¯({checkpoint_branch})ä¸å½“å‰åˆ†æ”¯({self.branch})ä¸åŒ¹é…!")
            print(f"âš ï¸  å°†åŠ è½½æ£€æŸ¥ç‚¹åˆ†æ”¯çš„æƒé‡ï¼Œä½†å¯èƒ½æ— æ³•å®Œå…¨å…¼å®¹")

        # æ£€æŸ¥æ£€æŸ¥ç‚¹ç±»å‹ï¼šå®Œæ•´æ¨¡å‹è¿˜æ˜¯åˆ†æ”¯æ¨¡å‹
        is_branch_checkpoint = 'branch_state_dict' in checkpoint
        
        if is_branch_checkpoint:
            print("ğŸ“¦ åŠ è½½åˆ†æ”¯ä¸“ç”¨æ£€æŸ¥ç‚¹...")
            # åˆ†æ”¯ä¸“ç”¨æ£€æŸ¥ç‚¹
            branch_state_dict = checkpoint['branch_state_dict']
            
            # å°†åˆ†æ”¯æƒé‡æ˜ å°„å›å®Œæ•´æ¨¡å‹
            if self.branch == "root":
                prefix = "root_decoder."
            elif self.branch == "trans":
                prefix = "trans_decoder."
            elif self.branch == "pose":
                prefix = "pose_decoder."
            
            full_state_dict = self.decoder.state_dict()
            loaded_count = 0
            
            for key, value in branch_state_dict.items():
                full_key = prefix + key
                if full_key in full_state_dict:
                    full_state_dict[full_key] = value
                    loaded_count += 1
            
            print(f"  âœ“ åŠ è½½äº† {loaded_count} ä¸ªåˆ†æ”¯å‚æ•°")
            
            # åŠ è½½æ¨¡å‹æƒé‡
            self.decoder.load_state_dict(full_state_dict, strict=False)
            
            # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
            if 'optimizer_state_dict' in checkpoint:
                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                for state in self.optimizer.state.values():
                    for k, v in state.items():
                        if isinstance(v, torch.Tensor):
                            state[k] = v.to(self.device)
        else:
            print("ğŸ“¦ åŠ è½½å®Œæ•´æ¨¡å‹æ£€æŸ¥ç‚¹...")
            # å®Œæ•´æ¨¡å‹æ£€æŸ¥ç‚¹
            self.decoder.load_state_dict(checkpoint['decoder_state_dict'], strict=False)

            # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
            if 'optimizer_state_dict' in checkpoint:
                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                for state in self.optimizer.state.values():
                    for k, v in state.items():
                        if isinstance(v, torch.Tensor):
                            state[k] = v.to(self.device)

        # åŠ è½½è°ƒåº¦å™¨çŠ¶æ€
        if 'scheduler_state_dict' in checkpoint:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        # åŠ è½½è®­ç»ƒå†å²
        self.loss_history = checkpoint.get('loss_history', [])
        self.depth_history = checkpoint.get('depth_history', [])
        self.lr_history = checkpoint.get('lr_history', [])

        # åŠ è½½è®­ç»ƒçŠ¶æ€
        self.epoch_counter = checkpoint.get('epoch_counter', 0)
        self.last_depth_increase_epoch = checkpoint.get('last_depth_increase_epoch', 0)
        self.best_loss = checkpoint.get('best_loss', float('inf'))
        self.stagnation_counter = checkpoint.get('stagnation_counter', 0)
        self.last_improvement_epoch = checkpoint.get('last_improvement_epoch', 0)
        self.consecutive_check_failures = checkpoint.get('consecutive_check_failures', 0)  # æ–°å¢

        checkpoint_target_loss = checkpoint.get('target_loss', None)
        checkpoint_max_depth = checkpoint.get('max_depth', None)
        checkpoint_consecutive_failures = checkpoint.get('consecutive_failures_required', None)

        print(f"âœ“ è®­ç»ƒçŠ¶æ€åŠ è½½å®Œæˆ:")
        print(f"  å·²è®­ç»ƒepoch: {self.epoch_counter}")
        print(f"  æœ€åå¢åŠ æ·±åº¦epoch: {self.last_depth_increase_epoch}")
        print(f"  å½“å‰æ·±åº¦: {self._get_current_depth()}å±‚")
        print(f"  æœ€ä½³æŸå¤±: {self.best_loss:.6f}")
        print(f"  è¿ç»­å¤±è´¥æ¬¡æ•°: {self.consecutive_check_failures}")

        # æ‰“å°å‚æ•°å¯¹æ¯”
        if checkpoint_target_loss is not None and checkpoint_target_loss != self.target_loss:
            print(f"  ğŸ“Š ç›®æ ‡æŸå¤±: æ£€æŸ¥ç‚¹={checkpoint_target_loss}, ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°={self.target_loss}")
        if checkpoint_max_depth is not None and checkpoint_max_depth != self.max_depth:
            print(f"  ğŸ“ æœ€å¤§æ·±åº¦: æ£€æŸ¥ç‚¹={checkpoint_max_depth}, ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°={self.max_depth}")
        if checkpoint_consecutive_failures is not None and checkpoint_consecutive_failures != self.consecutive_failures_required:
            print(
                f"  âš ï¸  è¿ç»­å¤±è´¥è¦æ±‚: æ£€æŸ¥ç‚¹={checkpoint_consecutive_failures}, ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°={self.consecutive_failures_required}")

        # ç§»åŠ¨æ¨¡å‹åˆ°æ­£ç¡®çš„è®¾å¤‡
        self.decoder = self.decoder.to(self.device)

    def setup_interrupt_handler(self):
        """è®¾ç½®ä¸­æ–­ä¿¡å·å¤„ç†"""

        def signal_handler(sig, frame):
            print(f"\næ¥æ”¶åˆ°ä¸­æ–­ä¿¡å· (Ctrl+C)")
            self.interrupted = True

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

    def _add_depth(self, num_layers=1):
        """ä¸ºå½“å‰åˆ†æ”¯å¢åŠ æ·±åº¦"""
        current_depth = self._get_current_depth()
        new_depth = current_depth + num_layers

        if new_depth > self.max_depth:
            print(f"âš ï¸  å·²è¾¾åˆ°æœ€å¤§æ·±åº¦ {self.max_depth}å±‚")
            return False

        print(f"ğŸ”§ ä¸º{self.branch}åˆ†æ”¯å¢åŠ æ·±åº¦: {current_depth} -> {new_depth}å±‚")

        # è°ƒç”¨æ¨¡å‹çš„æ–¹æ³•å¢åŠ æ·±åº¦
        if self.branch == "root":
            success = self.decoder.root_decoder.add_res_layers(num_layers=num_layers)
        elif self.branch == "trans":
            success = self.decoder.trans_decoder.add_res_layers(num_layers=num_layers)
        elif self.branch == "pose":
            success = self.decoder.pose_decoder.add_res_layers(num_layers=num_layers)
        else:
            success = False

        if success:
            # é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°å™¨
            self.consecutive_check_failures = 0
            print(f"âœ“ {self.branch}åˆ†æ”¯æ·±åº¦å¢åŠ åˆ° {new_depth}å±‚")
            print(f"âœ“ è¿ç»­å¤±è´¥è®¡æ•°å™¨å·²é‡ç½®")

            # é‡æ–°åˆ›å»ºä¼˜åŒ–å™¨ï¼ŒåŒ…å«æ–°å±‚çš„å‚æ•°
            self._recreate_optimizer()

            return True
        return False

    def _recreate_optimizer(self):
        """é‡æ–°åˆ›å»ºä¼˜åŒ–å™¨ï¼ŒåŒ…å«æ–°å±‚çš„å‚æ•°"""
        # è·å–å½“å‰åˆ†æ”¯çš„å‚æ•°
        if self.branch == "root":
            branch_params = list(self.decoder.root_decoder.parameters())
        elif self.branch == "trans":
            branch_params = list(self.decoder.trans_decoder.parameters())
        elif self.branch == "pose":
            branch_params = list(self.decoder.pose_decoder.parameters())

        # ä¿å­˜å½“å‰å­¦ä¹ ç‡
        if self.optimizer.param_groups:
            current_lr = self.optimizer.param_groups[0]['lr']
        else:
            current_lr = 1e-4

        # åˆ›å»ºæ–°çš„ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            branch_params,
            lr=current_lr,
            weight_decay=1e-5
        )

        print(f"ğŸ”§ é‡æ–°åˆ›å»ºä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡: {current_lr:.2e}")

    def prepare_batch(self, batch):
        """å‡†å¤‡æ‰¹æ¬¡æ•°æ®"""
        try:
            def to_device(obj):
                if isinstance(obj, torch.Tensor):
                    if obj.dtype in [torch.int32, torch.int64, torch.int16, torch.int8, torch.uint8]:
                        return obj.to(self.device)
                    else:
                        return obj.to(self.device).float()
                elif isinstance(obj, dict):
                    return {k: to_device(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [to_device(item) for item in obj]
                else:
                    return obj

            batch = to_device(batch)

            latent = batch['latent']

            if latent.dim() == 4:
                if latent.shape[0] == 128:
                    latent = latent.unsqueeze(0)
                else:
                    latent = latent.unsqueeze(-1)
            elif latent.dim() == 3:
                latent = latent.unsqueeze(0).unsqueeze(-1)
            elif latent.dim() == 5:
                pass
            else:
                raise ValueError(f"latentç»´åº¦åº”ä¸º5ï¼Œå½“å‰ä¸º{latent.dim()}")

            latents = latent.float()

            # æ ¹æ®åˆ†æ”¯è·å–ç›®æ ‡æ•°æ®
            if self.branch == "root":
                target = batch['root_orient'].float()
            elif self.branch == "trans":
                target = batch['trans'].float()
            elif self.branch == "pose":
                target = batch['pose_body'].float()

            valid_mask = batch.get('valid_mask', None)
            if valid_mask is not None:
                valid_mask = valid_mask.float()

            B, C, T_latent, H, W = latents.shape

            timestep = torch.rand(B, device=self.device)

            metadata = {
                'valid_mask': valid_mask,
                'num_persons': batch.get('num_persons', torch.tensor([2], device=self.device, dtype=torch.int64))
            }

            return latents, target, timestep, metadata
        except Exception as e:
            print(f"å‡†å¤‡æ‰¹æ¬¡æ•°æ®å¤±è´¥: {e}")
            traceback.print_exc()
            return None, None, None, None

    def train_epoch(self, dataloader: DataLoader) -> float:
        """è®­ç»ƒä¸€ä¸ªepochï¼Œè¿”å›æŸå¤±"""
        self.decoder.train()

        total_loss = 0
        num_batches = 0

        pbar = tqdm(dataloader, desc=f"Epoch {self.epoch_counter + 1}")
        for batch_idx, batch in enumerate(pbar):
            if self.interrupted:
                print("æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·")
                return total_loss / max(num_batches, 1)

            try:
                latents, target, timestep, metadata = self.prepare_batch(batch)

                if latents is None:
                    continue

                valid_mask = metadata.get('valid_mask')

                num_persons_tensor = metadata['num_persons']
                batch_size = latents.shape[0]

                file_ids = batch.get('file_id', [])
                if any('placeholder' in fid for fid in file_ids):
                    continue

                # è®¡ç®—è§£ç å™¨æœŸæœ›çš„ç›®æ ‡å¸§æ•°
                temporal_factor = getattr(self.decoder, 'temporal_downscale_factor', 8)
                T_latent = latents.shape[2]
                decoder_target_frames = (T_latent - 1) * temporal_factor + 1

                # å‰å‘ä¼ æ’­ - åªè®¡ç®—å½“å‰åˆ†æ”¯
                self.optimizer.zero_grad()

                if self.branch == "root":
                    output = self.decoder.root_decoder(
                        latents,
                        target_shape=(batch_size, 3, decoder_target_frames, 1, batch['num_persons'][0]),
                        timestep=timestep
                    )
                elif self.branch == "trans":
                    output = self.decoder.trans_decoder(
                        latents,
                        target_shape=(batch_size, 3, decoder_target_frames, 1, batch['num_persons'][0]),
                        timestep=timestep
                    )
                elif self.branch == "pose":
                    pose_dim = target.shape[-1]  # ä»ç›®æ ‡æ•°æ®è·å–poseç»´åº¦
                    output = self.decoder.pose_decoder(
                        latents,
                        target_shape=(batch_size, pose_dim, decoder_target_frames, 1, batch['num_persons'][0]),
                        timestep=timestep
                    )

                # è®¡ç®—æŸå¤±
                batch_loss = 0
                total_valid_persons = 0

                for sample_idx in range(batch_size):
                    num_persons_current = int(num_persons_tensor[sample_idx].item())

                    for person_idx in range(num_persons_current):
                        # è·å–é¢„æµ‹å€¼
                        if self.branch == "root":
                            pred = output[sample_idx:sample_idx + 1, :, :, :, person_idx]
                            pred = pred.squeeze(-1).squeeze(-1).permute(0, 2, 1)
                        elif self.branch == "trans":
                            pred = output[sample_idx:sample_idx + 1, :, :, :, person_idx]
                            pred = pred.squeeze(-1).squeeze(-1).permute(0, 2, 1)
                        elif self.branch == "pose":
                            pred = output[sample_idx:sample_idx + 1, :, :, :, person_idx]
                            pred = pred.squeeze(-1).squeeze(-1).permute(0, 2, 1)

                        # è·å–GTå€¼
                        person_target = target[sample_idx:sample_idx + 1, person_idx, :, :]

                        # å¯¹é½æ—¶é—´ç»´åº¦
                        if pred.shape[1] != person_target.shape[1]:
                            if pred.shape[1] > person_target.shape[1]:
                                person_target = torch.nn.functional.interpolate(
                                    person_target.permute(0, 2, 1),
                                    size=pred.shape[1],
                                    mode='linear',
                                    align_corners=False
                                ).permute(0, 2, 1)
                            else:
                                pred = torch.nn.functional.interpolate(
                                    pred.permute(0, 2, 1),
                                    size=person_target.shape[1],
                                    mode='linear',
                                    align_corners=False
                                ).permute(0, 2, 1)

                        # è°ƒæ•´æœ‰æ•ˆæ©ç 
                        scale_factor = 1.0
                        if valid_mask is not None:
                            if valid_mask.dim() == 3:
                                person_valid_mask = valid_mask[sample_idx:sample_idx + 1, person_idx, :]
                            else:
                                person_valid_mask = valid_mask[sample_idx:sample_idx + 1, :]

                            if person_valid_mask.shape[1] != pred.shape[1]:
                                person_valid_mask = torch.nn.functional.interpolate(
                                    person_valid_mask.unsqueeze(1),
                                    size=pred.shape[1],
                                    mode='nearest'
                                ).squeeze(1)

                            valid_ratio = person_valid_mask.mean()
                            if valid_ratio < 0.5:
                                scale_factor = valid_ratio

                        # è®¡ç®—æŸå¤±
                        loss = self.loss_fn(pred, person_target) * scale_factor
                        batch_loss += loss
                        total_valid_persons += 1

                # å¹³å‡æŸå¤±
                if total_valid_persons > 0:
                    batch_loss = batch_loss / total_valid_persons

                    # åå‘ä¼ æ’­
                    batch_loss.backward()

                    # æ¢¯åº¦è£å‰ª
                    if self.branch == "root":
                        torch.nn.utils.clip_grad_norm_(self.decoder.root_decoder.parameters(), max_norm=1.0)
                    elif self.branch == "trans":
                        torch.nn.utils.clip_grad_norm_(self.decoder.trans_decoder.parameters(), max_norm=1.0)
                    elif self.branch == "pose":
                        torch.nn.utils.clip_grad_norm_(self.decoder.pose_decoder.parameters(), max_norm=1.0)

                    # ä¼˜åŒ–å™¨æ­¥è¿›
                    self.optimizer.step()

                    # æ›´æ–°ç»Ÿè®¡
                    total_loss += batch_loss.item()
                    num_batches += 1

                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.set_postfix({
                        f'{self.branch}_loss': batch_loss.item(),
                        'depth': self._get_current_depth()
                    })

            except Exception as e:
                print(f"\næ‰¹å¤„ç† {batch_idx} è®­ç»ƒå¤±è´¥: {e}")
                traceback.print_exc()
                continue

        if num_batches > 0:
            return total_loss / num_batches
        else:
            return 0.0

    def should_increase_depth(self, current_loss, epoch):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¢åŠ æ·±åº¦"""
        if current_loss <= self.target_loss:
            print(f"ğŸ¯ å·²è¾¾åˆ°ç›®æ ‡æŸå¤± {current_loss:.6f} â‰¤ {self.target_loss}")
            return False

        if self._is_at_max_depth():
            print(f"ğŸ“ å·²è¾¾åˆ°æœ€å¤§æ·±åº¦ {self.max_depth}å±‚")
            return False

        epochs_since_last_increase = epoch - self.last_depth_increase_epoch
        if epochs_since_last_increase < self.min_epochs_after_depth_increase:
            remaining = self.min_epochs_after_depth_increase - epochs_since_last_increase
            print(f"â³ è·ç¦»ä¸Šæ¬¡å¢åŠ æ·±åº¦ä»… {epochs_since_last_increase} ä¸ªepochï¼Œ"
                  f"è¿˜éœ€è®­ç»ƒ {remaining} ä¸ªepochæ‰èƒ½å†æ¬¡å¢åŠ æ·±åº¦")
            return False

        if len(self.loss_history) < self.patience + 1:
            return False

        recent_losses = self.loss_history[-(self.patience + 1):]
        improvements = []

        for i in range(1, len(recent_losses)):
            improvement = recent_losses[i - 1] - recent_losses[i]
            improvements.append(improvement)

        avg_improvement = sum(improvements) / len(improvements) if improvements else 0

        print(f"ğŸ“Š æ·±åº¦åˆ¤æ–­: å½“å‰æŸå¤± {current_loss:.6f}, "
              f"æœ€è¿‘{self.patience}ä¸ªepochå¹³å‡æ”¹å–„ {avg_improvement:.6f}, "
              f"é˜ˆå€¼ {self.min_improvement}")
        print(f"ğŸ“Š è¿ç»­å¤±è´¥æ¬¡æ•°: {self.consecutive_check_failures}/{self.consecutive_failures_required}")

        # æ£€æŸ¥æ”¹å–„æ˜¯å¦è¾¾æ ‡
        improvement_met = avg_improvement >= self.min_improvement

        if not improvement_met:
            # æ”¹å–„ä¸è¾¾æ ‡ï¼Œå¢åŠ è¿ç»­å¤±è´¥è®¡æ•°
            self.consecutive_check_failures += 1
            print(
                f"âš ï¸  æ”¹å–„ä¸è¾¾æ ‡ï¼Œè¿ç»­å¤±è´¥æ¬¡æ•°: {self.consecutive_check_failures}/{self.consecutive_failures_required}")
        else:
            # æ”¹å–„è¾¾æ ‡ï¼Œé‡ç½®è¿ç»­å¤±è´¥è®¡æ•°
            self.consecutive_check_failures = 0
            print(f"âœ“ æ”¹å–„è¾¾æ ‡ï¼Œé‡ç½®è¿ç»­å¤±è´¥è®¡æ•°å™¨")

        # åªæœ‰è¿ç»­å¤±è´¥æ¬¡æ•°è¾¾åˆ°è¦æ±‚æ—¶æ‰å¢åŠ æ·±åº¦
        should_increase = (self.consecutive_check_failures >= self.consecutive_failures_required)

        if should_increase:
            print(f"ğŸ“ˆ å»ºè®®å¢åŠ æ·±åº¦: è¿ç»­ {self.consecutive_check_failures} æ¬¡æ£€æŸ¥ä¸è¾¾æ ‡")

        return should_increase

    def elastic_training_step(self, current_loss, epoch):
        """å¼¹æ€§è®­ç»ƒæ­¥éª¤ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦å¢åŠ æ·±åº¦"""
        self.loss_history.append(current_loss)

        if current_loss <= self.target_loss:
            print(f"\nğŸ‰ è¾¾åˆ°ç›®æ ‡æŸå¤±: {current_loss:.6f} â‰¤ {self.target_loss}")
            return False

        if self.should_increase_depth(current_loss, epoch):
            if self._add_depth(num_layers=1):
                current_depth = self._get_current_depth()
                self.depth_history.append({
                    'epoch': epoch + 1,
                    'depth': current_depth,
                    'loss': current_loss
                })

                self.last_depth_increase_epoch = epoch + 1

                print(f"\nğŸ”§ å¼¹æ€§å¢åŠ æ·±åº¦: {current_depth}å±‚ (epoch: {epoch + 1})")

                # ç¡®ä¿æ–°å±‚åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
                self.decoder = self.decoder.to(self.device)

                # è°ƒæ•´å­¦ä¹ ç‡
                self._adjust_learning_rate(0.8)

                return True

        return False

    def _adjust_learning_rate(self, factor: float):
        """è°ƒæ•´å­¦ä¹ ç‡"""
        for param_group in self.optimizer.param_groups:
            param_group['lr'] *= factor
        current_lr = self.optimizer.param_groups[0]['lr']
        self.lr_history.append(current_lr)
        print(f"ğŸ“‰ å­¦ä¹ ç‡è°ƒæ•´ä¸º: {current_lr:.2e}")

    def save_checkpoint(self, save_dir: Path, epoch: int, loss: float):
        """ä¿å­˜æ£€æŸ¥ç‚¹ - åªä¿å­˜å½“å‰è®­ç»ƒåˆ†æ”¯çš„æƒé‡"""
        save_dir.mkdir(parents=True, exist_ok=True)

        # åªä¿å­˜å½“å‰è®­ç»ƒåˆ†æ”¯çš„æƒé‡
        checkpoint_path = save_dir / f"{self.branch}_checkpoint_epoch{epoch:03d}.pt"

        original_device = self.device
        if original_device != "cpu":
            self.decoder = self.decoder.cpu()

        # æå–å½“å‰åˆ†æ”¯çš„çŠ¶æ€å­—å…¸
        branch_state_dict = self._extract_branch_state_dict()
        
        checkpoint = {
            'epoch': epoch,
            'branch_state_dict': branch_state_dict,  # åªåŒ…å«å½“å‰åˆ†æ”¯çš„æƒé‡
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'loss': loss,
            'current_depth': self._get_current_depth(),
            'depth_history': self.depth_history,
            'loss_history': self.loss_history,
            'lr_history': self.lr_history,
            'target_loss': self.target_loss,
            'max_depth': self.max_depth,
            'best_loss': self.best_loss,
            'stagnation_counter': self.stagnation_counter,
            'last_improvement_epoch': self.last_improvement_epoch,
            'epoch_counter': self.epoch_counter,
            'last_depth_increase_epoch': self.last_depth_increase_epoch,
            'learning_rate': self.optimizer.param_groups[0]['lr'],
            'min_epochs_after_depth_increase': self.min_epochs_after_depth_increase,
            'patience': self.patience,
            'min_improvement': self.min_improvement,
            'consecutive_failures_required': self.consecutive_failures_required,
            'consecutive_check_failures': self.consecutive_check_failures,
            'branch': self.branch,
            'is_branch_checkpoint': True,  # æ ‡è®°ä¸ºåˆ†æ”¯æ£€æŸ¥ç‚¹
        }

        torch.save(checkpoint, checkpoint_path)

        if original_device != "cpu":
            self.decoder = self.decoder.to(original_device)

        # ä¿å­˜é…ç½®ä¿¡æ¯
        config_path = save_dir / f"{self.branch}_config_epoch{epoch:03d}.json"
        with open(config_path, 'w') as f:
            config_data = {
                'epoch': epoch,
                'loss': loss,
                'current_depth': self._get_current_depth(),
                'depth_history': self.depth_history,
                'target_loss': self.target_loss,
                'max_depth': self.max_depth,
                'min_epochs_after_depth_increase': self.min_epochs_after_depth_increase,
                'patience': self.patience,
                'min_improvement': self.min_improvement,
                'consecutive_failures_required': self.consecutive_failures_required,
                'consecutive_check_failures': self.consecutive_check_failures,
                'branch': self.branch,
                'is_branch_checkpoint': True,
                'checkpoint_type': 'branch_only',
                'model_config': self.decoder.to_json_string() if hasattr(self.decoder, 'to_json_string') else {},
            }
            json.dump(config_data, f, indent=2)

        print(f"\nğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: epoch {epoch}")
        print(f"  ğŸ“ è·¯å¾„: {checkpoint_path}")
        print(f"  ğŸ“Š {self.branch}æŸå¤±: {loss:.6f}")
        print(f"  ğŸ“ å½“å‰æ·±åº¦: {self._get_current_depth()}å±‚")
        print(f"  âš ï¸  è¿ç»­å¤±è´¥æ¬¡æ•°: {self.consecutive_check_failures}/{self.consecutive_failures_required}")
        print(f"  ğŸ“Š åˆ†æ”¯å‚æ•°æ•°é‡: {len(branch_state_dict)}å±‚")
        
        return checkpoint_path

    def train(
            self,
            train_loader: DataLoader,
            num_epochs: int,
            save_dir: str,
            save_freq: int = 5,
            start_epoch: int = None
    ):
        """ä¸»è®­ç»ƒå¾ªç¯ - åªä¿å­˜å½“å‰è®­ç»ƒåˆ†æ”¯çš„æƒé‡"""
        print(f"\nğŸ¯ å¼€å§‹å¼¹æ€§è®­ç»ƒ{self.branch}åˆ†æ”¯")
        print(f"ğŸ“Š è®­ç»ƒé›†: {len(train_loader.dataset)} æ ·æœ¬")
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å¼: åªä¿å­˜{self.branch}åˆ†æ”¯æƒé‡")

        if start_epoch is None:
            start_epoch = self.epoch_counter
        actual_epochs = num_epochs - start_epoch

        print(f"â³ æ€»epochæ•°: {num_epochs} (ä»{start_epoch}å¼€å§‹ï¼Œå®é™…è®­ç»ƒ{actual_epochs}ä¸ªepoch)")
        print(f"ğŸ¯ ç›®æ ‡{self.branch}æŸå¤±: {self.target_loss}")
        print(f"ğŸ“ æœ€å¤§æ·±åº¦: {self.max_depth}å±‚")
        print(f"â±ï¸  å¢åŠ æ·±åº¦åæœ€å°‘è®­ç»ƒepoch: {self.min_epochs_after_depth_increase}")
        print(f"âš ï¸  è¿ç»­å¤±è´¥è¦æ±‚: {self.consecutive_failures_required}æ¬¡")
        print(f"ğŸ’¾ ä¿å­˜é¢‘ç‡: æ¯{save_freq}ä¸ªepoch")
        print("=" * 60)

        save_dir = Path(save_dir)

        try:
            for epoch in range(start_epoch, num_epochs):
                self.epoch_counter = epoch + 1

                if self.interrupted:
                    print("æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œä¿å­˜æ£€æŸ¥ç‚¹...")
                    if len(self.loss_history) > 0:
                        last_loss = self.loss_history[-1]
                        self.save_checkpoint(save_dir, epoch + 1, last_loss)
                    break

                print(f"\n{'=' * 50}")
                print(f"Epoch {epoch + 1}/{num_epochs} (å…¨å±€: {self.epoch_counter})")
                print(f"è®­ç»ƒåˆ†æ”¯: {self.branch}")
                print(f"å½“å‰æ·±åº¦: {self._get_current_depth()}å±‚")
                print(f"å½“å‰å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.2e}")
                print(f"è¿ç»­å¤±è´¥æ¬¡æ•°: {self.consecutive_check_failures}/{self.consecutive_failures_required}")
                if self.last_depth_increase_epoch > 0:
                    epochs_since_increase = (epoch + 1) - self.last_depth_increase_epoch
                    print(f"è·ç¦»ä¸Šæ¬¡å¢åŠ æ·±åº¦: {epochs_since_increase}ä¸ªepoch")
                print(f"{'=' * 50}")

                # è®­ç»ƒä¸€ä¸ªepoch
                current_loss = self.train_epoch(train_loader)

                improvement = 0.0
                if len(self.loss_history) > 0:
                    last_loss = self.loss_history[-1]
                    improvement = last_loss - current_loss

                print(f"\nğŸ“Š è®­ç»ƒç»“æœ:")
                print(f"  {self.branch}æŸå¤±: {current_loss:.6f}")
                if len(self.loss_history) > 0:
                    print(f"  ğŸ“ˆ æ”¹å–„å€¼: {improvement:.6f} ({'+' if improvement > 0 else ''}{improvement:.6f})")

                # å¼¹æ€§è®­ç»ƒæ­¥éª¤
                depth_increased = self.elastic_training_step(current_loss, epoch)

                # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
                self.scheduler.step(current_loss)

                # æ›´æ–°æœ€ä½³æŸå¤±
                if current_loss < self.best_loss:
                    self.best_loss = current_loss
                    self.last_improvement_epoch = epoch + 1

                # ä¿å­˜æ£€æŸ¥ç‚¹
                save_this_epoch = (epoch + 1) % save_freq == 0 or depth_increased
                if save_this_epoch:
                    self.save_checkpoint(save_dir, epoch + 1, current_loss)

                # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
                latest_checkpoint = save_dir / f"latest_{self.branch}_checkpoint.pt"
                if latest_checkpoint.exists():
                    latest_checkpoint.unlink()
                latest_checkpoint_path = self.save_checkpoint(save_dir, epoch + 1, current_loss)
                if latest_checkpoint_path:
                    # é‡å‘½åä¸ºlatest
                    Path(latest_checkpoint_path).rename(latest_checkpoint)
                    print(f"  ğŸ”„ æ›´æ–°æœ€æ–°æ£€æŸ¥ç‚¹: {latest_checkpoint}")

                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
                if current_loss <= self.target_loss:
                    print(f"\n{'=' * 50}")
                    print(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼è¾¾åˆ°ç›®æ ‡{self.branch}æŸå¤±")
                    print(f"ğŸ“Š æœ€ç»ˆ{self.branch}æŸå¤±: {current_loss:.6f}")
                    print(f"ğŸ“ æœ€ç»ˆæ·±åº¦: {self._get_current_depth()}å±‚")
                    print(f"ğŸ“… è®­ç»ƒæ€»epoch: {self.epoch_counter}")
                    print(f"{'=' * 50}")

                    # ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹
                    final_path = self.save_checkpoint(save_dir, epoch + 1, current_loss)
                    final_checkpoint = save_dir / f"final_{self.branch}_checkpoint.pt"
                    if final_checkpoint.exists():
                        final_checkpoint.unlink()
                    Path(final_path).rename(final_checkpoint)
                    print(f"ğŸ’¾ ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹: {final_checkpoint}")

                    break

                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§epoch
                if epoch + 1 >= num_epochs:
                    print(f"\n{'=' * 50}")
                    print(f"âš ï¸ è¾¾åˆ°æœ€å¤§epochæ•°")
                    print(f"ğŸ“Š æœ€ç»ˆ{self.branch}æŸå¤±: {current_loss:.6f}")
                    print(f"ğŸ“ æœ€ç»ˆæ·±åº¦: {self._get_current_depth()}å±‚")
                    print(f"ğŸ“… è®­ç»ƒæ€»epoch: {self.epoch_counter}")
                    print(f"{'=' * 50}")

                    self.save_checkpoint(save_dir, epoch + 1, current_loss)

                # æ£€æŸ¥ä¸­æ–­
                if self.interrupted:
                    print("æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œä¿å­˜æ£€æŸ¥ç‚¹...")
                    self.save_checkpoint(save_dir, epoch + 1, current_loss)
                    break

        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­è®­ç»ƒ")
            if len(self.loss_history) > 0:
                last_loss = self.loss_history[-1]
                self.save_checkpoint(save_dir, self.epoch_counter, last_loss)

        except Exception as e:
            print(f"\nè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            traceback.print_exc()
            if len(self.loss_history) > 0:
                last_loss = self.loss_history[-1]
                self.save_checkpoint(save_dir, self.epoch_counter, last_loss)


def create_elastic_decoder_from_config(
        max_depth: int = 8,
        initial_depth: int = 2,
        branch: str = "root"
):
    """ä»é…ç½®åˆ›å»ºå…¨æ–°çš„å¼¹æ€§è§£ç å™¨"""
    print(f"ğŸ“¥ åˆ›å»ºå…¨æ–°çš„å¼¹æ€§è§£ç å™¨")

    config = create_elastic_motion_decoder_config(
        latent_channels=128,
        motion_channels_per_person=69,
        base_channels=128,
        causal=True,
        timestep_conditioning=True,
        dropout_rate=0.1,
        use_weight_decay=True,
        use_layer_norm=False,
        use_stochastic_depth=True,
        stochastic_depth_rate=0.1,
        max_res_layers=max_depth,
        initial_res_layers=initial_depth,
        use_elastic_depth=True,
    )

    decoder = ElasticMotionDecoder.from_config(config)

    print(f"âœ“ åˆ›å»ºå¼¹æ€§è§£ç å™¨æˆåŠŸ")
    print(f"  ğŸ“ æœ€å¤§æ·±åº¦: {max_depth}å±‚")
    print(f"  ğŸ“ åˆå§‹æ·±åº¦: {initial_depth}å±‚")
    print(f"  ğŸ”§ è®­ç»ƒåˆ†æ”¯: {branch}")

    return decoder


def create_elastic_trainer_from_checkpoint(
        checkpoint_path: str,
        branch: str = "root",
        device: str = "cuda",
        train_loader: DataLoader = None,
        # æ–°å¢ï¼šå…è®¸ä¼ é€’å‘½ä»¤è¡Œå‚æ•°æ¥è¦†ç›–æ£€æŸ¥ç‚¹ä¸­çš„å€¼
        max_depth: int = None,
        target_loss: float = None,
        patience: int = None,
        min_improvement: float = None,
        min_epochs_after_depth_increase: int = None,
        consecutive_failures_required: int = None,
        learning_rate: float = None
):
    """ä»æ£€æŸ¥ç‚¹åˆ›å»ºå¼¹æ€§è®­ç»ƒå™¨ï¼ˆç”¨äºæ–­ç‚¹ç»­è®­ï¼‰"""
    print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹åˆ›å»º{branch}è®­ç»ƒå™¨: {checkpoint_path}")

    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=True)

    # æ£€æŸ¥æ£€æŸ¥ç‚¹ç±»å‹
    is_branch_checkpoint = checkpoint.get('is_branch_checkpoint', False)
    print(f"  ğŸ“¦ æ£€æŸ¥ç‚¹ç±»å‹: {'åˆ†æ”¯ä¸“ç”¨' if is_branch_checkpoint else 'å®Œæ•´æ¨¡å‹'}")

    # ä»æ£€æŸ¥ç‚¹è·å–åˆ†æ”¯ä¿¡æ¯
    checkpoint_branch = checkpoint.get('branch', branch)
    if checkpoint_branch != branch:
        print(f"âš ï¸  è­¦å‘Š: æ£€æŸ¥ç‚¹åˆ†æ”¯({checkpoint_branch})ä¸æŒ‡å®šåˆ†æ”¯({branch})ä¸åŒ¹é…!")
        print(f"âš ï¸  å°†ä½¿ç”¨æ£€æŸ¥ç‚¹åˆ†æ”¯: {checkpoint_branch}")
        branch = checkpoint_branch

    current_depth = checkpoint.get('current_depth', 2)

    # ä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ£€æŸ¥ç‚¹ä¸­çš„å€¼
    effective_max_depth = max_depth if max_depth is not None else checkpoint.get('max_depth', 8)
    effective_target_loss = target_loss if target_loss is not None else checkpoint.get('target_loss', 0.01)
    effective_patience = patience if patience is not None else checkpoint.get('patience', 5)
    effective_min_improvement = min_improvement if min_improvement is not None else checkpoint.get('min_improvement',
                                                                                                   0.001)
    effective_min_epochs = min_epochs_after_depth_increase if min_epochs_after_depth_increase is not None else checkpoint.get(
        'min_epochs_after_depth_increase', 30)
    effective_consecutive_failures = consecutive_failures_required if consecutive_failures_required is not None else checkpoint.get(
        'consecutive_failures_required', 3)
    effective_learning_rate = learning_rate if learning_rate is not None else checkpoint.get('learning_rate', 1e-4)

    # ç›´æ¥ä»æ£€æŸ¥ç‚¹æ¢å¤æ¨¡å‹
    config = create_elastic_motion_decoder_config(
        latent_channels=128,
        motion_channels_per_person=69,
        base_channels=128,
        causal=True,
        timestep_conditioning=True,
        dropout_rate=0.1,
        use_weight_decay=True,
        use_layer_norm=False,
        use_stochastic_depth=True,
        stochastic_depth_rate=0.1,
        max_res_layers=effective_max_depth,  # ä½¿ç”¨æœ‰æ•ˆçš„æœ€å¤§æ·±åº¦
        initial_res_layers=current_depth,
        use_elastic_depth=True,
    )

    decoder = ElasticMotionDecoder.from_config(config)

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ElasticBranchDecoderTrainer(
        decoder=decoder,
        branch=branch,
        device=device,
        learning_rate=effective_learning_rate,
        target_loss=effective_target_loss,
        patience=effective_patience,
        min_improvement=effective_min_improvement,
        max_depth=effective_max_depth,
        min_epochs_after_depth_increase=effective_min_epochs,
        consecutive_failures_required=effective_consecutive_failures,
        checkpoint_path=checkpoint_path,
    )

    print(f"âœ“ {branch}è®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
    print(f"  å½“å‰æ·±åº¦: {trainer._get_current_depth()}å±‚")
    print(f"  å·²è®­ç»ƒepoch: {trainer.epoch_counter}")
    print(f"  è¿ç»­å¤±è´¥æ¬¡æ•°: {trainer.consecutive_check_failures}/{effective_consecutive_failures}")
    print(f"  ä½¿ç”¨çš„æœ€å¤§æ·±åº¦: {effective_max_depth}å±‚ (å‘½ä»¤è¡Œå‚æ•°è¦†ç›–)")

    return trainer


def collate_fn(batch):
    """æ‰¹æ¬¡æ•´ç†å‡½æ•°"""
    batch = [b for b in batch if b is not None]
    if not batch:
        return _create_placeholder_batch()

    max_T_latent = max([item['T_latent'] for item in batch])
    max_target_frames = max([item['root_orient'].shape[1] for item in batch])

    batched = {}

    # å¤„ç†latent
    latents = []
    for item in batch:
        latent = item['latent']
        C, T, H, W = latent.shape

        if T < max_T_latent:
            pad_size = max_T_latent - T
            padding = torch.zeros(C, pad_size, H, W, dtype=latent.dtype)
            latent = torch.cat([latent, padding], dim=1)

        latents.append(latent)

    batched['latent'] = torch.stack(latents)

    # å¤„ç†æ‰€æœ‰è¿åŠ¨å‚æ•°
    root_orients = []
    pose_bodies = []
    trans_list = []
    valid_masks = []
    T_latents = []
    target_frames = []
    num_persons = []

    for item in batch:
        root_orient = item['root_orient']
        pose_body = item['pose_body']
        trans = item['trans']
        num_persons_current = root_orient.shape[0]

        # å¤„ç†root_orient
        T_root, D_root = root_orient.shape[1], root_orient.shape[2]
        if T_root < max_target_frames:
            pad_size = max_target_frames - T_root
            padding = torch.zeros(num_persons_current, pad_size, D_root, dtype=root_orient.dtype)
            root_orient = torch.cat([root_orient, padding], dim=1)
        root_orients.append(root_orient)

        # å¤„ç†pose_body
        T_pose, D_pose = pose_body.shape[1], pose_body.shape[2]
        if T_pose < max_target_frames:
            pad_size = max_target_frames - T_pose
            padding = torch.zeros(num_persons_current, pad_size, D_pose, dtype=pose_body.dtype)
            pose_body = torch.cat([pose_body, padding], dim=1)
        pose_bodies.append(pose_body)

        # å¤„ç†trans
        T_trans, D_trans = trans.shape[1], trans.shape[2]
        if T_trans < max_target_frames:
            pad_size = max_target_frames - T_trans
            padding = torch.zeros(num_persons_current, pad_size, D_trans, dtype=trans.dtype)
            trans = torch.cat([trans, padding], dim=1)
        trans_list.append(trans)

        if 'valid_mask' in item:
            valid_mask = item['valid_mask']
            if valid_mask.shape[1] < max_target_frames:
                pad_size = max_target_frames - valid_mask.shape[1]
                padding = torch.zeros(num_persons_current, pad_size, dtype=valid_mask.dtype)
                valid_mask = torch.cat([valid_mask, padding], dim=1)
            valid_masks.append(valid_mask)

        T_latents.append(item['T_latent'])
        target_frames.append(item['target_frames'])
        num_persons.append(num_persons_current)

    batched['root_orient'] = torch.stack(root_orients)
    batched['pose_body'] = torch.stack(pose_bodies)
    batched['trans'] = torch.stack(trans_list)

    if valid_masks:
        batched['valid_mask'] = torch.stack(valid_masks)

    batched['T_latent'] = torch.tensor(T_latents, dtype=torch.int64)
    batched['target_frames'] = torch.tensor(target_frames, dtype=torch.int64)
    batched['num_persons'] = torch.tensor(num_persons, dtype=torch.int64)
    batched['file_id'] = [item['file_id'] for item in batch]

    return batched


def _create_placeholder_batch():
    """åˆ›å»ºä¸€ä¸ªå ä½ç¬¦æ‰¹æ¬¡"""
    C = 128
    T_latent = 8
    T_target = (T_latent - 1) * 8 + 1
    pose_dim = 63

    return {
        'latent': torch.randn(1, C, T_latent, 1, 1),
        'root_orient': torch.zeros(1, 2, T_target, 3),
        'pose_body': torch.zeros(1, 2, T_target, pose_dim),
        'trans': torch.zeros(1, 2, T_target, 3),
        'valid_mask': torch.ones(1, 2, T_target),
        'T_latent': torch.tensor([T_latent], dtype=torch.int64),
        'target_frames': torch.tensor([T_target], dtype=torch.int64),
        'num_persons': torch.tensor([2], dtype=torch.int64),
        'file_id': ['placeholder_batch']
    }


def main():
    parser = argparse.ArgumentParser(description="å¼¹æ€§è®­ç»ƒæŒ‡å®šåˆ†æ”¯ï¼Œå½“è®­ç»ƒä¸‹é™ç¼“æ…¢æ—¶å¢åŠ æ·±åº¦ï¼Œæ”¯æŒæ–­ç‚¹ç»­è®­")

    # æ•°æ®å‚æ•°
    parser.add_argument("--features_dir", type=str, required=True,
                        help="latentç‰¹å¾æ–‡ä»¶ç›®å½•")
    parser.add_argument("--gt_dir", type=str, required=True,
                        help="GTè¿åŠ¨å‚æ•°ç›®å½•")
    parser.add_argument("--interpolate_method", type=str, default="linear",
                        choices=["linear", "cubic"], help="æ’å€¼æ–¹æ³•")

    # è®­ç»ƒåˆ†æ”¯é€‰æ‹©
    parser.add_argument("--branch", type=str, required=True,
                        choices=["root", "trans", "pose"],
                        help="è®­ç»ƒçš„åˆ†æ”¯ï¼šroot/trans/pose")

    # è®­ç»ƒå‚æ•°
    parser.add_argument("--batch_size", type=int, default=4,
                        help="æ‰¹å¤§å°")
    parser.add_argument("--num_epochs", type=int, default=100,
                        help="è®­ç»ƒepochæ•°")
    parser.add_argument("--learning_rate", type=float, default=1e-4,
                        help="å­¦ä¹ ç‡")
    parser.add_argument("--num_workers", type=int, default=4,
                        help="æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°")

    # å¼¹æ€§è®­ç»ƒå‚æ•°
    parser.add_argument("--target_loss", type=float, default=0.01,
                        help="ç›®æ ‡æŸå¤±ï¼ˆå½“è¾¾åˆ°æ­¤å€¼æ—¶åœæ­¢è®­ç»ƒï¼‰")
    parser.add_argument("--patience", type=int, default=5,
                        help="è€å¿ƒå€¼ï¼ˆå¤šå°‘ä¸ªepochç”¨äºè®¡ç®—å¹³å‡æ”¹å–„ï¼‰")
    parser.add_argument("--min_improvement", type=float, default=0.001,
                        help="æœ€å°æ”¹å–„é˜ˆå€¼ï¼ˆå°äºæ­¤å€¼è®¤ä¸ºåœæ»ï¼‰")
    parser.add_argument("--max_depth", type=int, default=8,
                        help="æœ€å¤§æ·±åº¦é™åˆ¶")
    parser.add_argument("--initial_depth", type=int, default=2,
                        help="åˆå§‹æ·±åº¦")
    parser.add_argument("--min_epochs_after_depth_increase", type=int, default=30,
                        help="å¢åŠ æ·±åº¦åè‡³å°‘è®­ç»ƒçš„epochæ•°")
    parser.add_argument("--consecutive_failures_required", type=int, default=3,
                        help="è¿ç»­æ£€æŸ¥ä¸è¾¾æ ‡æ¬¡æ•°è¦æ±‚ï¼ˆé»˜è®¤3æ¬¡ï¼‰")

    # ä¿å­˜å‚æ•°
    parser.add_argument("--save_dir", type=str, default="./decoder_training",
                        help="ä¿å­˜ç›®å½•")
    parser.add_argument("--save_freq", type=int, default=5,
                        help="ä¿å­˜é¢‘ç‡ï¼ˆepochï¼‰")

    # æ–­ç‚¹ç»­è®­å‚æ•°
    parser.add_argument("--resume", type=str, default=None,
                        help="ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼Œä¾‹å¦‚: ./decoder_training/latest_root_checkpoint.pt")

    # è®¾å¤‡
    parser.add_argument("--device", type=str, default="cuda",
                        help="è®¾å¤‡ï¼ˆcuda/cpuï¼‰")

    args = parser.parse_args()

    print("=" * 60)
    print(f"å¼¹æ€§{args.branch}åˆ†æ”¯è®­ç»ƒ - æ”¯æŒæ–­ç‚¹ç»­è®­")
    print("=" * 60)
    print(f"è®­ç»ƒåˆ†æ”¯: {args.branch}")
    print(f"ç‰¹å¾ç›®å½•: {args.features_dir}")
    print(f"GTç›®å½•: {args.gt_dir}")
    if args.resume:
        print(f"æ¢å¤æ£€æŸ¥ç‚¹: {args.resume}")
    print(f"æ‰¹å¤§å°: {args.batch_size}")
    print(f"Epochæ•°: {args.num_epochs}")
    print(f"å­¦ä¹ ç‡: {args.learning_rate}")
    print(f"\nğŸ¯ è®­ç»ƒç›®æ ‡:")
    print(f"  è®­ç»ƒåˆ†æ”¯: {args.branch}")
    print(f"  ç›®æ ‡æŸå¤±: {args.target_loss}")
    print(f"  æœ€å¤§æ·±åº¦: {args.max_depth}å±‚")
    print(f"  åˆå§‹æ·±åº¦: {args.initial_depth}å±‚")
    print(f"  è€å¿ƒå€¼: {args.patience}ä¸ªepoch")
    print(f"  æœ€å°æ”¹å–„é˜ˆå€¼: {args.min_improvement}")
    print(f"  å¢åŠ æ·±åº¦åæœ€å°‘è®­ç»ƒepoch: {args.min_epochs_after_depth_increase}")
    print(f"  è¿ç»­å¤±è´¥è¦æ±‚: {args.consecutive_failures_required}æ¬¡")
    print(f"ğŸ“Š ä¿å­˜é…ç½®:")
    print(f"  ä¿å­˜ç›®å½•: {args.save_dir}")
    print(f"  ä¿å­˜é¢‘ç‡: æ¯{args.save_freq}ä¸ªepoch")
    print(f"  æ£€æŸ¥ç‚¹ç±»å‹: åªä¿å­˜{args.branch}åˆ†æ”¯æƒé‡")  # ä¿®å¤è¿™é‡Œï¼Œä½¿ç”¨args.branch
    print("=" * 60)

    # è®¾ç½®è®¾å¤‡
    device = args.device
    if device == "cuda" and not torch.cuda.is_available():
        print("è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        device = "cpu"

    # åˆ›å»ºæ•°æ®é›†
    print("\nåˆ›å»ºæ•°æ®é›†...")
    dataset = LTXMotionDataset(
        features_dir=args.features_dir,
        gt_dir=args.gt_dir,
        temporal_factor=8,
        interpolate_method=args.interpolate_method
    )

    train_loader = DataLoader(
        dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True,
        drop_last=True,
        collate_fn=collate_fn
    )

    print(f"è®­ç»ƒé›†: {len(dataset)} æ ·æœ¬")

    # æ£€æŸ¥æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    if args.resume and os.path.exists(args.resume):
        print(f"\nğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume}")
        trainer = create_elastic_trainer_from_checkpoint(
            checkpoint_path=args.resume,
            branch=args.branch,
            device=device,
            train_loader=train_loader,
            max_depth=args.max_depth,
            target_loss=args.target_loss,
            patience=args.patience,
            min_improvement=args.min_improvement,
            min_epochs_after_depth_increase=args.min_epochs_after_depth_increase,
            consecutive_failures_required=args.consecutive_failures_required,
            learning_rate=args.learning_rate
        )

        # è®¡ç®—å‰©ä½™çš„è®­ç»ƒepochæ•°
        remaining_epochs = max(0, args.num_epochs - trainer.epoch_counter)
        if remaining_epochs == 0:
            print(f"âš ï¸  æ£€æŸ¥ç‚¹å·²ç»è®­ç»ƒäº† {trainer.epoch_counter} ä¸ªepochï¼Œå·²è¾¾åˆ°ç›®æ ‡ {args.num_epochs}")
            print("å¦‚æœè¦ç»§ç»­è®­ç»ƒï¼Œè¯·å¢åŠ  --num_epochs å‚æ•°")
            return

        print(f"ç»§ç»­è®­ç»ƒå‰©ä½™ {remaining_epochs} ä¸ªepoch (æ€»è®¡: {args.num_epochs})")

    else:
        # åˆ›å»ºå…¨æ–°çš„å¼¹æ€§è§£ç å™¨
        print("\nåˆ›å»ºå…¨æ–°çš„å¼¹æ€§è§£ç å™¨...")
        decoder = create_elastic_decoder_from_config(
            max_depth=args.max_depth,
            initial_depth=args.initial_depth,
            branch=args.branch
        )

        # ç»Ÿè®¡å‚æ•°
        total_params = sum(p.numel() for p in decoder.parameters())
        root_params = sum(p.numel() for p in decoder.root_decoder.parameters())
        trans_params = sum(p.numel() for p in decoder.trans_decoder.parameters())
        pose_params = sum(p.numel() for p in decoder.pose_decoder.parameters())

        print(f"\nğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
        print(f"  æ€»å‚æ•°: {total_params:,}")
        print(f"  rootè§£ç å™¨: {root_params:,}")
        print(f"  transè§£ç å™¨: {trans_params:,}")
        print(f"  poseè§£ç å™¨: {pose_params:,}")
        print(f"  å½“å‰è®­ç»ƒåˆ†æ”¯: {args.branch}")
        print(f"  å½“å‰æ·±åº¦: {decoder.get_current_depth()}å±‚")

        # åˆ›å»ºè®­ç»ƒå™¨
        print(f"\nåˆ›å»º{args.branch}è®­ç»ƒå™¨...")
        trainer = ElasticBranchDecoderTrainer(
            decoder=decoder,
            branch=args.branch,
            device=device,
            learning_rate=args.learning_rate,
            target_loss=args.target_loss,
            patience=args.patience,
            min_improvement=args.min_improvement,
            max_depth=args.max_depth,
            min_epochs_after_depth_increase=args.min_epochs_after_depth_increase,
            consecutive_failures_required=args.consecutive_failures_required,
            checkpoint_path=None,
        )

    # å¼€å§‹è®­ç»ƒ
    try:
        trainer.train(
            train_loader=train_loader,
            num_epochs=args.num_epochs,
            save_dir=args.save_dir,
            save_freq=args.save_freq,
            start_epoch=trainer.epoch_counter
        )

        print(f"\nè®­ç»ƒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {args.save_dir}")

        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        if trainer.depth_history:
            print(f"\nğŸ“ˆ æ·±åº¦å†å²è®°å½•:")
            for record in trainer.depth_history:
                print(f"  Epoch {record['epoch']}: {record['depth']}å±‚, "
                      f"{args.branch}æŸå¤±: {record['loss']:.6f}")

        print(f"\nğŸ“‹ è®­ç»ƒæ€»ç»“:")
        print(f"  è®­ç»ƒåˆ†æ”¯: {args.branch}")
        print(f"  è®­ç»ƒæ€»epochæ•°: {trainer.epoch_counter}")
        print(f"  æœ€ç»ˆ{args.branch}æŸå¤±: {trainer.loss_history[-1] if trainer.loss_history else 'N/A':.6f}")
        print(f"  æœ€ç»ˆæ·±åº¦: {trainer._get_current_depth()}å±‚")
        print(f"  æœ€ä½³æŸå¤±: {trainer.best_loss:.6f}")
        print(f"  æ·±åº¦å¢åŠ æ¬¡æ•°: {len(trainer.depth_history)}æ¬¡")
        print(f"  è¿ç»­å¤±è´¥æœ€å¤§æ¬¡æ•°: {trainer.consecutive_check_failures}æ¬¡")
        print(f"  ä¿å­˜æ¨¡å¼: åªä¿å­˜{args.branch}åˆ†æ”¯æƒé‡")  # ä¿®å¤è¿™é‡Œï¼Œä½¿ç”¨args.branch

        # è¾“å‡ºæ–‡ä»¶åˆ—è¡¨
        print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        save_dir = Path(args.save_dir)
        if save_dir.exists():
            checkpoint_files = list(save_dir.glob("*checkpoint*.pt"))
            config_files = list(save_dir.glob("*config*.json"))
            
            if checkpoint_files:
                print(f"  æ£€æŸ¥ç‚¹æ–‡ä»¶ ({len(checkpoint_files)}ä¸ª):")
                for file in sorted(checkpoint_files)[-5:]:  # æ˜¾ç¤ºæœ€å5ä¸ªæ–‡ä»¶
                    file_size = file.stat().st_size / (1024 * 1024)  # MB
                    print(f"    - {file.name} ({file_size:.2f} MB)")
            
            if config_files:
                print(f"  é…ç½®æ–‡ä»¶ ({len(config_files)}ä¸ª):")
                for file in sorted(config_files)[-3:]:  # æ˜¾ç¤ºæœ€å3ä¸ªæ–‡ä»¶
                    print(f"    - {file.name}")

    except Exception as e:
        print(f"\nä¸»è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
        print("ç¨‹åºé€€å‡º")


if __name__ == "__main__":
    main()